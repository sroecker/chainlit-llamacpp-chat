# chainlit-llamacpp-chat
Local chat with llama.cpp issues
